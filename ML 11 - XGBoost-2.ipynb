{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d1205b3-7cb0-4bb2-8df6-23dc599c68c3",
     "showTitle": false,
     "title": "--i18n-b9944704-a562-44e0-8ef6-8639f11312ca"
    }
   },
   "source": [
    "# XGBoost\n",
    "\n",
    "Up until this point, we have only used SparkML. Let's look a third party library for Gradient Boosted Trees. \n",
    " \n",
    "Ensure that you are using the <a href=\"https://docs.microsoft.com/en-us/azure/databricks/runtime/mlruntime\" target=\"_blank\">Databricks Runtime for ML</a> because that has Distributed XGBoost already installed. \n",
    "\n",
    "**Question**: How do gradient boosted trees differ from random forests? Which parts can be parallelized?\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Learning Objectives:<br>\n",
    "\n",
    "By the end of this lesson, you should be able to;\n",
    "\n",
    "* Build a XGBoost model and integrate it into Spark ML pipeline\n",
    "* Evaluate XGBoost model performance\n",
    "* Compare and contrast most common gradient boosted approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2686462-858e-43fa-a51e-dca27ac9cf14",
     "showTitle": false,
     "title": "--i18n-1e2c921e-1125-4df3-b914-d74bf7a73ab5"
    }
   },
   "source": [
    "## ðŸ“Œ Requirements\n",
    "\n",
    "**Required Databricks Runtime Version:** \n",
    "* Please note that in order to run this notebook, you must use one of the following Databricks Runtime(s): **12.2.x-cpu-ml-scala2.12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c3f6f8a-3e0d-452d-82f0-abbe23387702",
     "showTitle": false,
     "title": "--i18n-6a1bb996-7b50-4f03-9bcd-3d3ec3069a6d"
    }
   },
   "source": [
    "## Lesson Setup\n",
    "\n",
    "The first thing we're going to do is to **run setup script**. This script will define the required configuration variables that are scoped to each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47931388-7d33-4179-9c3e-ef2ffdbc3043",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c580df70-f7f2-469c-8ee9-d29ec4322f4a",
     "showTitle": false,
     "title": "--i18n-3e08ca45-9a00-4c6a-ac38-169c7e87d9e4"
    }
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Let's go ahead and index all of our categorical features, and set our label to be **`log(price)`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e44146b-853c-4baf-84c7-473683a045a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log, col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "file_path = f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\n",
    "airbnb_df = spark.read.format(\"delta\").load(file_path)\n",
    "train_df, test_df = airbnb_df.withColumn(\"label\", log(col(\"price\"))).randomSplit([.8, .2], seed=42)\n",
    "\n",
    "categorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\n",
    "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
    "\n",
    "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n",
    "\n",
    "numeric_cols = [field for (field, dataType) in train_df.dtypes if ((dataType == \"double\") & (field != \"price\") & (field != \"label\"))]\n",
    "assembler_inputs = index_output_cols + numeric_cols\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56616b74-356b-466c-9f67-1854c371318a",
     "showTitle": false,
     "title": "--i18n-733cd880-143d-42c2-9f29-602e48f60efe"
    }
   },
   "source": [
    "### Pyspark Distributed XGBoost\n",
    "\n",
    "Let's create our distributed XGBoost model. While technically not part of MLlib, you can integrate <a href=\"https://databricks.github.io/spark-deep-learning/_modules/sparkdl/xgboost/xgboost.html\" target=\"_blank\">XGBoost</a> into your ML Pipelines. \n",
    "\n",
    "To use the distributed version of Pyspark XGBoost you can specify two additional parameters:\n",
    "\n",
    "* **`num_workers`**: The number of workers to distribute over. Requires MLR 9.0+.\n",
    "* **`use_gpu`**: Enable to utilize GPU based training for faster performance (optional).\n",
    "\n",
    "**NOTE:** **`use_gpu`** requires an ML GPU runtime. Currently, at most one GPU per worker will be used when doing distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d6e67cd-46e0-4a4f-8021-c1e95ae9135d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sparkdl.xgboost import XgboostRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "params = {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"random_state\": 42, \"missing\": 0}\n",
    "\n",
    "xgboost = XgboostRegressor(**params)\n",
    "\n",
    "pipeline = Pipeline(stages=[string_indexer, vec_assembler, xgboost])\n",
    "pipeline_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8e29c5a-4475-4552-9bb4-0a7be9bd0372",
     "showTitle": false,
     "title": "--i18n-8d5f8c24-ee0b-476e-a250-95ce2d73dd28"
    }
   },
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Now we can evaluate how well our XGBoost model performed. Don't forget to exponentiate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ef7daf-f122-4a1b-8078-05fa724d7414",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import exp, col\n",
    "\n",
    "log_pred_df = pipeline_model.transform(test_df)\n",
    "\n",
    "exp_xgboost_df = log_pred_df.withColumn(\"prediction\", exp(col(\"prediction\")))\n",
    "\n",
    "display(exp_xgboost_df.select(\"price\", \"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dae15ee-429b-44d7-a4f0-90ae58e87d66",
     "showTitle": false,
     "title": "--i18n-364402e1-8073-4b24-8e03-c7e2566f94d2"
    }
   },
   "source": [
    "Compute some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bb3b396-4159-40a9-a9db-f7a03c46f398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
    "\n",
    "rmse = regression_evaluator.evaluate(exp_xgboost_df)\n",
    "r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_xgboost_df)\n",
    "print(f\"RMSE is {rmse}\")\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dea4081-ad1d-4924-89c2-ae03ff73dffa",
     "showTitle": false,
     "title": "--i18n-21cf0d1b-c7a8-43c0-8eea-7677bb0d7847"
    }
   },
   "source": [
    "## Alternative Gradient Boosted Approaches\n",
    "\n",
    "There are lots of other gradient boosted approaches, such as <a href=\"https://catboost.ai/\" target=\"_blank\">CatBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\" target=\"_blank\">LightGBM</a>, vanilla gradient boosted trees in <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html?highlight=gbt#pyspark.ml.classification.GBTClassifier\" target=\"_blank\">SparkML</a>/<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\" target=\"_blank\">scikit-learn</a>, etc. Each of these has their respective <a href=\"https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\" target=\"_blank\">pros and cons</a> that you can read more about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc9fc3d8-d012-4792-b5a3-f913f8f7a5bd",
     "showTitle": false,
     "title": "--i18n-a2c7fb12-fd0b-493f-be4f-793d0a61695b"
    }
   },
   "source": [
    "## Classroom Cleanup\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d44031b-8844-429a-9b68-f12905e9d596",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cac193e-a7cb-4e75-bc4b-d3b2cd48ecc6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML 11 - XGBoost",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
